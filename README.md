# Search Agent

## ğŸ“Œ Description
Search Agent est une application permettant d'exÃ©cuter des recherches spÃ©cifiques en utilisant Streamlit et Docker. Cette application est contenue dans un conteneur Docker pour faciliter son dÃ©ploiement et son exÃ©cution. Elle intÃ¨gre des modÃ¨les de recherche comme Llama et Ollama, offrant une interface simple pour interagir avec ces outils.

## ğŸš€ FonctionnalitÃ©s
- **Interface utilisateur avec Streamlit** : L'interface est dÃ©veloppÃ©e avec Streamlit pour une expÃ©rience fluide et interactive.
- **Containerisation avec Docker** : L'application est contenue dans un conteneur Docker pour faciliter le dÃ©ploiement sur n'importe quelle machine sans dÃ©pendances supplÃ©mentaires.
- **IntÃ©gration avec Llama et Ollama** : Le projet utilise des modÃ¨les Llama et Ollama pour effectuer des recherches avancÃ©es sur les donnÃ©es.

### ğŸŒ¦ï¸ **Weather Tool** 
- **API UtilisÃ©e** : WeatherAPI
- **FonctionnalitÃ©s** :
  - RÃ©cupÃ©ration en temps rÃ©el des donnÃ©es mÃ©tÃ©o
  - Support multi-villes (Paris, Lyon, Marseille...)
  - Affichage des donnÃ©es claires :
    - TempÃ©rature (Â°C)
    - Conditions atmosphÃ©riques
    - Vitesse du vent
  - Gestion d'erreur robuste avec fallback manuel

### ğŸ” **Search Tool** 
- **API UtilisÃ©e** : Tavily Search API
- **FonctionnalitÃ©s** :
  - Recherche web avancÃ©e
  - Extraction des 3 premiers rÃ©sultats pertinents
  - Filtrage intelligent des sources touristiques
  - Cache des requÃªtes pour performance
  - Fallback vers Google Search si Ã©chec

### ğŸ§  **Moteur d'Intelligence Artificielle**
- **Technologies** :
  - **LangChain** : Orchestration des composants AI
  - **LangGraph** : Gestion des workflows complexes
  - **Ollama** : HÃ©bergement local des modÃ¨les LLM

- **ModÃ¨les UtilisÃ©s** :
  - `llama3` (8B paramÃ¨tres) - ModÃ¨le principal
  - `mistral` (7B paramÃ¨tres) - Alternative lÃ©gÃ¨re
  - `french-llama` - OptimisÃ© pour le franÃ§ais

- **FonctionnalitÃ©s AI** :
  - Analyse sÃ©mantique des requÃªtes
  - Fusion intelligente des rÃ©sultats (mÃ©tÃ©o + web)
  - GÃ©nÃ©ration de rÃ©ponses naturelles en franÃ§ais
  - SystÃ¨me de fallback contextuel

### ğŸ–¥ï¸ **Interface Utilisateur**
- Framework : **Streamlit**
- FonctionnalitÃ©s :
  - Saisie de requÃªte naturelle
  - Affichage contextuel des rÃ©sultats
  - Indicateurs visuels de statut
  - Adaptatif mobile/desktop
  - Temps de rÃ©ponse visible

### ğŸ³ **Infrastructure**
- Containerisation via **Docker**
- Gestion des dÃ©pendances :
  - Isolation des environnements
  - DÃ©ploiement simplifiÃ©
  - Configuration via variables d'environnement

## ğŸ›  Installation et utilisation

### 1ï¸âƒ£ **Cloner le projet**
```sh
git clone https://github.com/belaid-sarah/agent.git
cd nom-du-repo

## ğŸ¦™ Commandes Ollama

### TÃ©lÃ©charger les modÃ¨les :
```bash
ollama pull llama3     # ModÃ¨le principal (7B paramÃ¨tres)
ollama pull mistral    # ModÃ¨le alternatif (7B paramÃ¨tres)

ollama serve           # Lancer en premier plan

streamlit run app.py     #run the app
